{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2827b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3789e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f87bcf8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>PCOS</th>\n",
       "      <th>age</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>fbs</th>\n",
       "      <th>ca</th>\n",
       "      <th>chol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>26.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>26.6</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>26.6</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>5441</td>\n",
       "      <td>24.1</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>5454</td>\n",
       "      <td>29.3</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>5490</td>\n",
       "      <td>22.9</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>5492</td>\n",
       "      <td>22.9</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>5496</td>\n",
       "      <td>22.9</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1085 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   BMI  Glucose  PCOS  age  cp  trestbps  fbs  ca  chol\n",
       "0              0  26.6       85     0   35   0       120    0   0   198\n",
       "1              2  26.6       85     0   35   0       138    0   0   183\n",
       "2              4  26.6       85     0   35   1       122    0   0   192\n",
       "3              8  26.6       85     0   35   0       126    0   0   282\n",
       "4             60  26.6       81     0   35   0       120    0   0   198\n",
       "...          ...   ...      ...   ...  ...  ..       ...  ...  ..   ...\n",
       "1080        5441  24.1      140     0   48   1       110    0   0   229\n",
       "1081        5454  29.3      149     1   29   1       130    0   0   204\n",
       "1082        5490  22.9      175     0   34   1       118    0   0   210\n",
       "1083        5492  22.9      175     0   34   3       118    0   0   182\n",
       "1084        5496  22.9      175     0   29   1       130    0   0   204\n",
       "\n",
       "[1085 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Copy of finaldataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbaa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop('PCOS',axis=1)\n",
    "y=data.PCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1239e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(x,y,random_state=104,test_size=0.25,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4c4010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[251   0]\n",
      " [  4  17]]\n",
      "Accuracy: 0.9852941176470589\n",
      "F1 score: 0.8947368421052632\n",
      "Recall: 0.8095238095238095\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Random forest:\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(criterion=\"entropy\")  \n",
    "  \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    "  \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('confusion matrix',confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2780f459",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#learning curve for Random forest\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ShuffleSplit\n\u001b[0;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m common_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m }\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#learning curve for Random forest\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([clf]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1e8650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[251   0]\n",
      " [  4  17]]\n",
      "Accuracy: 0.9852941176470589\n",
      "F1 score: 0.8947368421052632\n",
      "Recall: 0.8095238095238095\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting:\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5, max_depth=1)\n",
    "gbc.fit(X_train, np.ravel(y_train, order='C'))\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('confusion matrix',confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcfe3381",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#learning curve for Gradient boosting\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ShuffleSplit\n\u001b[0;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m common_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m }\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#learning curve for Gradient boosting\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([gbc]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40593b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[250   1]\n",
      " [ 16   5]]\n",
      "Accuracy: 0.9375\n",
      "F1 score: 0.37037037037037035\n",
      "Recall: 0.23809523809523808\n",
      "Precision: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# k nearest neighbour \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('confusion matrix',confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378aa657",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#learning curve for knn\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ShuffleSplit\n\u001b[0;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m common_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m }\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#learning curve for knn\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([knn]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2fbea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[248   3]\n",
      " [ 13   8]]\n",
      "Accuracy: 0.9411764705882353\n",
      "F1 score: 0.5\n",
      "Recall: 0.38095238095238093\n",
      "Precision: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression \n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(max_iter=3000)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#predict \n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('confusion matrix',confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c23fc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#learning curve for Logistic Regression \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ShuffleSplit\n\u001b[0;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m common_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m }\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#learning curve for Logistic Regression \n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([model]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c925de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[247   4]\n",
      " [ 12   9]]\n",
      "Accuracy: 0.9411764705882353\n",
      "F1 score: 0.5294117647058824\n",
      "Recall: 0.42857142857142855\n",
      "Precision: 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "svm = SVC(kernel='linear') \n",
    "  \n",
    "# fitting x samples and y classes \n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred=svm.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('confusion matrix',confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4536e4c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#learning curve for svm\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ShuffleSplit\n\u001b[0;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m common_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m }\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LearningCurveDisplay' from 'sklearn.model_selection' (C:\\Users\\91824\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#learning curve for svm\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([svm]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70406ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "dtree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtree.fit(X_train, y_train)\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print('confusion matrix',confusion_matrix(y_test,y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6211ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curve for decision tree\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([dtree]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d41553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# hybrid RFLR \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a hybrid random forest logistic regression model\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the random forest to generate new features for logistic regression\n",
    "rf_features = rf.apply(X_train)\n",
    "X_train_new = X_train.copy()\n",
    "X_train_new = np.concatenate((X_train_new, rf_features), axis=1)\n",
    "\n",
    "# Fit a logistic regression model on the new features\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_new, y_train)\n",
    "\n",
    "# Use the random forest and logistic regression models to make predictions on the test set\n",
    "rf_features_test = rf.apply(X_test)\n",
    "X_test_new = X_test.copy()\n",
    "X_test_new = np.concatenate((X_test_new, rf_features_test), axis=1)\n",
    "y_pred = lr.predict(X_test_new)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",acc)\n",
    "print('F1 score:', f1_score(y_test,y_pred ))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curve for hybrid rflr\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": x,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 10,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([lr]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f741d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMEANS\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, init ='k-means++', max_iter=300, n_init=10,random_state=0 )\n",
    "y_kmeans = kmeans.fit_predict(x)\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "print(f'Silhouette Score(n=2): {silhouette_score(x,y_kmeans)}')\n",
    "\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "print(f'davies_bouldin_score(n=2): {davies_bouldin_score(x,y_kmeans)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a11e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot for Kmeans\n",
    "from sklearn.decomposition import PCA\n",
    " \n",
    "pca = PCA(n_components = 2)\n",
    " \n",
    "pcaval= pca.fit_transform(data)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(pcaval)\n",
    "xpca=pcaval[:,0]\n",
    "ypca=pcaval[:,1]\n",
    "\n",
    "plt.scatter(xpca,ypca, c=kmeans.labels_)\n",
    "plt.title(\"Kmeans scatter plot for IF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ee0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "\n",
    "  #Create arrays from feature importance and feature names\n",
    "  feature_importance = np.array(importance)\n",
    "  feature_names = np.array(names)\n",
    "\n",
    "  #Create a DataFrame using a Dictionary\n",
    "  data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "  fi_df = pd.DataFrame(data)\n",
    "\n",
    "  #Sort the DataFrame in order decreasing feature importance\n",
    "  fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "  #Define size of bar plot\n",
    "  plt.figure(figsize=(8,6))\n",
    "  #Plot Searborn bar chart\n",
    "  sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "  #Add chart labels\n",
    "  plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "  plt.xlabel('FEATURE IMPORTANCE')\n",
    "  plt.ylabel('FEATURE NAMES')\n",
    "\n",
    "plot_feature_importance(clf.feature_importances_,X_train.columns,'RANDOM FOREST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "distortions = []\n",
    "inertias = []\n",
    "mapping1 = {}\n",
    "mapping2 = {}\n",
    "K = range(1, 10)\n",
    "  \n",
    "for k in K:\n",
    "    # Building and fitting the model\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(x)\n",
    "    kmeanModel.fit(x)\n",
    "  \n",
    "    distortions.append(((sum(np.min(cdist(x, kmeanModel.cluster_centers_,'euclidean'), axis=1)) / x.shape[0])/100))\n",
    "    inertias.append(kmeanModel.inertia_)\n",
    "  \n",
    "    mapping1[k] = sum(np.min(cdist(x, kmeanModel.cluster_centers_,'euclidean'), axis=1)) / x.shape[0]\n",
    "    mapping2[k] = kmeanModel.inertia_\n",
    "\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method using Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ed3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a92b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9093255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4893e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
